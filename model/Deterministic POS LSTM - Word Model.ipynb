{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic POS Word Level Language Model with Penn Treebank\n",
    "Sequence Tagger: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html<br>\n",
    "Penn Treebank: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.8216&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/williamFalcon/f27c7b90e34b4ba88ced042d9ef33edd <br>\n",
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import os\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /home/tyler/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/tyler/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc993cb5270>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An LSTM for Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penn tree bank\n",
    "sentences = treebank.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "samples = 5000\n",
    "sentences = sentences[:samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sequence(seq):\n",
    "    \"\"\"\n",
    "    Formats penn treebank POS format into tuple ([tokens], [POS])\n",
    "    \"\"\"\n",
    "    tokens = [x[0] for x in seq]\n",
    "    tags = [x[1] for x in seq]\n",
    "    return (tokens, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [format_sequence(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_vocab(sentences):\n",
    "    \"\"\"Builds vocab based on input data\"\"\"\n",
    "    vocab = dict()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence[0]:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab) + 1    # counts from 1+ as 0 is reserved for <PAD> token\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab of input data (this will likely be a subset of any word embedding array)\n",
    "data_vocab = data_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding token to data vocab\n",
    "data_vocab['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "split_ratio = 0.80\n",
    "training_data = sentences[:int(len(sentences)*split_ratio)]\n",
    "test_data = sentences[len(training_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: 3914 | Training Set Size: 3131 | Test Set Size: 783\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset Size: {len(sentences)} | Training Set Size: {len(training_data)} | Test Set Size: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"John likes the blue house at the end of the street\".split(), [\"NN\", \"V\", \"DET\", \"ADJ\", \"NN\", \"PREP\", \"DET\", \"NN\", \"PREP\", \"DET\", \"NN\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {}\n",
    "for sent, tags in sentences:   # training_data\n",
    "#     print(sent, tags)\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix) + 1\n",
    "# print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tag-index lookups\n",
    "tag_to_ix = {}\n",
    "for _, tags in sentences:\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_ix:\n",
    "            tag_to_ix[tag] = len(tag_to_ix) + 1\n",
    "\n",
    "ix_to_tag = {v:k for k, v in tag_to_ix.items()}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ix_to_tag = {0:\"DET\", 1:\"NN\", 2:\"V\", 3: \"ADJ\", 4: \"PREP\"}\n",
    "tag_to_ix = {\"DET\":0, \"NN\":1, \"V\":2, \"ADJ\": 3, \"PREP\":4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word dictionary size: 12408\n",
      "Tag dictionary size: 12\n"
     ]
    }
   ],
   "source": [
    "print(f'Word dictionary size: {len(word_to_ix)}')\n",
    "print(f'Tag dictionary size: {len(tag_to_ix)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding to word dict\n",
    "word_to_ix['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add padding to tag dict\n",
    "tag_to_ix['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    \"\"\"Encodes sentence tokens as ids from word_to_ix dictionary\"\"\"\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_seq_batch(batch, to_ix, pad_len, pad_token_id=0):\n",
    "    \"\"\"Encodes batch of sequences as ids from word_to_ix dictionary and pads\"\"\"\n",
    "    batch_size = len(batch)\n",
    "    padded_batch = np.full((batch_size, pad_len), pad_token_id)\n",
    "    seq_lens = [len(seq) for seq in batch]\n",
    "    \n",
    "    for i, seq in enumerate(batch):\n",
    "        # encode tokens as ids\n",
    "        idxs = [to_ix[w] for w in seq]    \n",
    "        # pad length\n",
    "        padded_batch[i,0:len(idxs)] = idxs\n",
    "        \n",
    "    return torch.tensor(padded_batch, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [sentences[0][0], sentences[1][0], sentences[2][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27, 28,  3, 29,  5,  6, 30, 31, 20, 21, 32, 33, 34, 35,  3, 36, 37, 38,\n",
       "        12, 13, 14, 21, 39, 40, 41, 42, 17])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sequence(sentences[2][0], word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  3,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [18,  2, 19, 20, 21, 22, 23,  3,  9, 24, 25, 26, 17,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [27, 28,  3, 29,  5,  6, 30, 31, 20, 21, 32, 33, 34, 35,  3, 36, 37, 38,\n",
       "         12, 13, 14, 21, 39, 40, 41, 42, 17,  0,  0,  0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_seq_batch(batch, word_to_ix, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets_batch(batch, to_ix, pad_len, pad_token_id=0):\n",
    "    \"\"\"Encodes batch of sequence targets as ids from target_to_ix dictionary and pads length\"\"\"\n",
    "    batch_size = len(batch)\n",
    "    padded_batch = np.full((batch_size, pad_len), pad_token_id)\n",
    "    targets_lens = [len(targets) for targets in batch]\n",
    "    \n",
    "    for i, targets in enumerate(batch):\n",
    "        # encode targets as ids\n",
    "        idxs = [to_ix[target] for target in targets]\n",
    "        # pad length\n",
    "        padded_batch[i, 0:len(idxs)] = idxs\n",
    "    \n",
    "    return torch.tensor(padded_batch, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_batch = [sentences[0][1], sentences[1][1], sentences[2][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 2, 3, 1, 4, 2, 5, 5, 6, 1, 7, 6, 4, 1, 1, 3, 2, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 5, 1, 7, 1, 1, 2, 6, 1, 5, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 2, 3, 1, 4, 8, 4, 1, 7, 1, 1, 1, 1, 2, 5, 5, 9, 6, 4, 1, 7, 6, 4,\n",
       "         4, 1, 2, 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_targets_batch(targets_batch, tag_to_ix, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader\n",
    "Something something data loader..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennTreeBankDataset(Dataset):\n",
    "    \"\"\"Penn Tree Bank dataset\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # download data, read, process\n",
    "        np_array = np.zeros((1000,10))\n",
    "        \n",
    "        # load Penn tree bank sentences\n",
    "        self.sentences = treebank.tagged_sents(tagset='universal')\n",
    "        self.sentences = [self.format_sequence(sentence) for sentence in self.sentences]\n",
    "        self.len = len(self.sentences)\n",
    "        \n",
    "        self.pad_token = '<PAD>'\n",
    "        self.pad_token_id = 0\n",
    "        self.pad_len = max([len(sentence[0]) for sentence in self.sentences])\n",
    "        \n",
    "        # Vocab of input data (this will likely be a subset of any word embedding array)\n",
    "        self.build_vocab()\n",
    "        self.create_word_to_idx_dict()\n",
    "        self.create_tag_to_idx_dict()\n",
    "        self.X, self.y, self.X_lens = self.encode_data()\n",
    "                \n",
    "    def info(self):\n",
    "        print(f'Word dictionary size: {len(word_to_ix)}') \n",
    "        print(f'Tag dictionary size: {len(tag_to_ix)}')\n",
    "        \n",
    "    def format_sequence(self,seq):\n",
    "        \"\"\"\n",
    "        Formats penn treebank POS format into tuple ([tokens], [POS])\n",
    "        \"\"\"\n",
    "        tokens = [x[0] for x in seq]\n",
    "        tags = [x[1] for x in seq]\n",
    "        return (tokens, tags)\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        \"\"\"Builds vocab based on input data\"\"\"\n",
    "        self.vocab = dict()\n",
    "        for sentence in self.sentences:\n",
    "            for word in sentence[0]:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.vocab) + 1    # counts from 1+ as 0 is reserved for PAD token\n",
    "        \n",
    "        # Add padding token to data vocab\n",
    "        self.vocab[self.pad_token] = 0\n",
    "    \n",
    "    def create_word_to_idx_dict(self):\n",
    "        self.word_to_idx = {}\n",
    "        for sentence, tags in self.sentences:\n",
    "            for word in sentence:\n",
    "                if word not in self.word_to_idx:\n",
    "                    self.word_to_idx[word] = len(self.word_to_idx) + 1    # counts from 1+ as 0 is reserved for PAD token\n",
    "        \n",
    "        # add padding to word dict\n",
    "        self.word_to_idx[self.pad_token] = 0\n",
    "        \n",
    "    def create_tag_to_idx_dict(self):\n",
    "        # Create tag-index lookups\n",
    "        self.tag_to_idx = {}\n",
    "        for _, tags in self.sentences:\n",
    "            for tag in tags:\n",
    "                if tag not in self.tag_to_idx:\n",
    "                    self.tag_to_idx[tag] = len(self.tag_to_idx) + 1    # counts from 1+ as 0 is reserved for PAD token\n",
    "\n",
    "        # add padding to tag dict\n",
    "        self.tag_to_idx[self.pad_token] = 0\n",
    "        self.idx_to_tag = {v:k for k, v in self.tag_to_idx.items()}\n",
    "\n",
    "    def encode_data(self):\n",
    "        \"\"\"Encodes data from text to indices. Padding will be on the fly with the NN model\"\"\"\n",
    "\n",
    "        seq_lengths = [len(seq) for seq in self.sentences]\n",
    "        \n",
    "        # encode\n",
    "        for i, (seq, tags) in enumerate(self.sentences):\n",
    "            seq_idxs = [self.word_to_idx[token] for token in seq]\n",
    "            tags_idxs = [self.tag_to_idx[tag] for tag in tags]        \n",
    "\n",
    "        return torch.tensor(seq_idxs, dtype=torch.long), torch.tensor(tags_idxs, dtype=torch.long), torch.tensor(seq_lengths, dtype=torch.int)\n",
    "        \n",
    "    def encode_and_pad_data(self):\n",
    "        \"\"\"Encodes data (seq and tags) into ids from id dictionary and pads\"\"\"\n",
    "        \"\"\"Pads both sentence and target sequences\"\"\"\n",
    "        \n",
    "        batch_size = len(self.sentences)\n",
    "\n",
    "        padded_seq_batch = np.full((batch_size, self.pad_len), self.pad_token_id)\n",
    "        padded_tags_batch = np.full((batch_size, self.pad_len), self.pad_token_id)\n",
    "        seq_lengths = [len(seq) for seq in self.sentences]\n",
    "        \n",
    "        # encode and pad\n",
    "        for i, (seq, tags) in enumerate(self.sentences):\n",
    "            # encode\n",
    "            seq_idxs = [self.word_to_idx[token] for token in seq]\n",
    "            tags_idxs = [self.tag_to_idx[tag] for tag in tags]        \n",
    "            # pad\n",
    "            padded_seq_batch[i,0:len(seq_idxs)] = seq_idxs\n",
    "            padded_tags_batch[i, 0:len(tags_idxs)] = tags_idxs\n",
    "            \n",
    "        return torch.tensor(padded_seq_batch, dtype=torch.long), torch.tensor(padded_tags_batch, dtype=torch.long), torch.tensor(seq_lengths, dtype=torch.int)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index], self.X_lens[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PennTreeBankDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset,\n",
    "                         batch_size=32,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Word Embeddings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def loadGloveModel(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(File,'r')\n",
    "    gloveModel = {}\n",
    "    for line in f:\n",
    "        splitLines = line.split()\n",
    "        word = splitLines[0]\n",
    "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "        gloveModel[word] = wordEmbedding\n",
    "    print(len(gloveModel),\" words loaded!\")\n",
    "    return gloveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_embeddings = './data/embeddings/glove.6B.300d.txt'\n",
    "path_to_trimmed_embeddings = './data/embeddings/trimmed_emb.npz'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gloveModel = loadGloveModel(path_to_embeddings)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "emb_vocab = set(gloveModel.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://github.com/Michael-Stewart-Webdev/pytorch-lexnorm/blob/master/build_data.py\n",
    "# https://leakyrelu.com/2019/10/18/using-glove-word-embeddings-with-seq2seq-encoder-decoder-in-pytorch/\n",
    "def export_emb_vectors(data_vocab, emb_filename, trimmed_emb_filename, dim):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    embeddings = np.zeros([len(data_vocab), dim])\n",
    "\n",
    "    with codecs.open(emb_filename, 'r', 'utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(' ')\n",
    "            word = line[0]\n",
    "            embedding = [float(x) for x in line[1:]]\n",
    "            if word in data_vocab:\n",
    "                word_idx = data_vocab[word]\n",
    "                clear_output(wait=True)\n",
    "                print(word, word_idx)\n",
    "                \n",
    "                embeddings[word_idx] = np.asarray(embedding)\n",
    "    \n",
    "    np.savez_compressed(trimmed_emb_filename, embeddings=embeddings)\n",
    "    print('Saved trimmed embeddings to disk')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "export_emb_vectors(data_vocab, path_to_embeddings, path_to_trimmed_embeddings, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 vocab,\n",
    "                 tags,\n",
    "                 batch_size=32,\n",
    "                 pretrained_embeddings=None):\n",
    "        \n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = 1\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.tags = tags\n",
    "        self.tagset_size = len(self.tags)\n",
    "        self.tagset_size = self.tagset_size - 1 # minus <TAG>\n",
    "        self.padding_idx = self.vocab['<PAD>']\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(num_embeddings=self.vocab_size,\n",
    "                                            embedding_dim=self.embedding_dim,\n",
    "                                            padding_idx=self.padding_idx)\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.word_embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "            self.word_embeddings.weight.requires_grad = False\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        # If batch_first is true the input/output tensors are provided as (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim,\n",
    "                            hidden_size=self.hidden_dim,\n",
    "                            num_layers=self.num_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.out = nn.Linear(in_features=self.hidden_dim,\n",
    "                             out_features=self.tagset_size)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \"\"\"\n",
    "        Initialises weights for hidden layers of LSTM\n",
    "        Weights are in the form of (num_layers, batch_size, embedding_dim)\"\"\"\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim), torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "    def forward(self, X, X_lengths):\n",
    "        \"\"\"\"\"\"\n",
    "        self.hidden = self.init_hidden()\n",
    "#         print('hidden shape:', self.hidden.shape)\n",
    "        \n",
    "        batch_size, seq_len = X.size()\n",
    "        \n",
    "        X = self.word_embeddings(X)\n",
    "        print('X size after embedding:', X.shape)\n",
    "        \n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(X, X_lengths, batch_first=True)\n",
    "        \n",
    "        X, self.hidden = self.lstm(X, self.hidden)\n",
    "        print('X size after lstm:', X.data.shape, 'X batch size after lstm:', X.batch_sizes.shape)\n",
    "\n",
    "        X, _ = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "        print('X size after pad_packed_seq:', X.shape)\n",
    "        \n",
    "        X = X.contiguous()\n",
    "        print('X shape after contiguous func:', X.shape)\n",
    "        X = X.view(-1, X.shape[2])\n",
    "        \n",
    "        X = self.out(X)\n",
    "        print('X shape after fc layer:', X.shape)\n",
    "        \n",
    "        X = F.log_softmax(X, dim=1)\n",
    "        \n",
    "#         X = X.view(batch_size, seq_len, self.tagset_size)\n",
    "        \n",
    "        Y_hat = X\n",
    "        return Y_hat\n",
    "    \n",
    "        \n",
    "    def loss(self, Y_hat, Y):\n",
    "        \"\"\"\"\"\"\n",
    "        \n",
    "        print('y_hat:',Y_hat.shape,'y:',Y.shape)\n",
    "        \n",
    "        Y = Y.view(-1)\n",
    "        \n",
    "        Y_hat = Y_hat.view(-1, self.tagset_size)\n",
    "        \n",
    "        tag_pad_token = self.tags['<PAD>']\n",
    "        mask = (Y > tag_pad_token).float()\n",
    "        \n",
    "        num_tokens = int(torch.sum(mask).data[0])\n",
    "        \n",
    "        Y_hat = Y_hat[range(Y_hat.shape[0]), Y] * mask\n",
    "        \n",
    "        ce_loss = -torch.sum(Y_hat) / num_tokens\n",
    "        \n",
    "        return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trimmed embeddings from disk\n",
    "pretrained_embeddings = np.load(path_to_trimmed_embeddings)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check embedding shape\n",
    "pretrained_embeddings['embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300   # Glove 300\n",
    "HIDDEN_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_net = LSTMTagger(embedding_dim=EMBEDDING_DIM,\n",
    "                      hidden_dim=HIDDEN_DIM,\n",
    "                      vocab=data_vocab,\n",
    "                      tags=tag_to_ix,\n",
    "                      pretrained_embeddings=pretrained_embeddings['embeddings'])\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(lstm_net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTagger(\n",
      "  (word_embeddings): Embedding(12409, 300, padding_idx=0)\n",
      "  (lstm): LSTM(300, 32, batch_first=True)\n",
      "  (out): Linear(in_features=32, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lstm_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train standard NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: torch.Size([32, 271]) targets: torch.Size([32, 271])\n",
      "X size after embedding: torch.Size([32, 271, 300])\n",
      "X shape after contiguous func: torch.Size([32, 271, 32])\n",
      "X shape after fc layer: torch.Size([8672, 12])\n",
      "tag_scores: torch.Size([8672, 12]) \n",
      "\n",
      "y_hat: torch.Size([8672, 12]) y: torch.Size([32, 271])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-725-c2ef6a93ee95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# compute loss, gradients and update parameters by calling optimzier.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-720-439eca45573f>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, Y_hat, Y)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtag_pad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mY_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for batch_idx, (data, targets, data_lens) in enumerate(train_loader, 0):\n",
    "\n",
    "        lstm_net.zero_grad()\n",
    "        \n",
    "#         data = data.reshape(data.shape[0], data.shape[1], -1)\n",
    "#         print(data.shape)\n",
    "        \n",
    "        # forward pass...\n",
    "        print('data:', data.shape, 'targets:', targets.shape)\n",
    "        \n",
    "        tag_scores = lstm_net(data, data_lens)\n",
    "        \n",
    "        print('tag_scores:',tag_scores.shape, '\\n')\n",
    "        \n",
    "        \n",
    "        # compute loss, gradients and update parameters by calling optimzier.step()\n",
    "        loss = lstm_net.loss(tag_scores, targets)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-e317af4cda8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Step 3. Run our forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Step 4. Compute the loss, gradients, and update the parameters by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-344e2ea7dedc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, X_lengths)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        lstm_net.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = lstm_net(sentence_in, len(sentence_in))\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch} - Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for deterministic nn inference\n",
    "def tag_score_to_tag_name(tag_score, ix_to_tag):\n",
    "    \"\"\"Converts tag score to tag names\"\"\"\n",
    "    return ix_to_tag.get(torch.argmax(tag_score).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single test example\n",
    "test_data_sm = test_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(test_data_sm[0][0], word_to_ix)\n",
    "    tag_scores = lstm_net(inputs)\n",
    "    \n",
    "#     print(f'Tag Scores:\\n{tag_scores}\\n')\n",
    "    print(f'{\"Token\":<20} {\"Pred\":<10} {\"Actual\":<10}')\n",
    "    print(f'{\"-----\":<20} {\"----\":<10} {\"------\":<10}')\n",
    "    for i, token in enumerate(training_data[0][0]):\n",
    "        print(f'{token:<20} {tag_score_to_tag_name(tag_scores[i], ix_to_tag):<10} {test_data_sm[0][1][i]:<10}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
